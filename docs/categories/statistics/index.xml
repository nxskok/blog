<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Statistics on R, it&#39;s OK I guess</title>
    <link>/categories/statistics/</link>
    <description>Recent content in Statistics on R, it&#39;s OK I guess</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 13 Jun 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/statistics/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Tidy matched pairs t-test</title>
      <link>/2018/06/13/tidy-matched-pairs-t-test/</link>
      <pubDate>Wed, 13 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/06/13/tidy-matched-pairs-t-test/</guid>
      <description>Introduction The matched pairs \(t\)-test is for comparing two measurements obtained on the same individual, such as a before and an after measurement. This is different from the two-sample \(t\)-test, which has two independent sets of measurements, one for each experimental condition, with each set collected on different individuals. The matched-pairs \(t\)-test is typically the first time we meet repeated-measures data (more than one measurement on the same individual, collected at different times or under different conditions), but we sidestep having to learn anything too new by looking at the difference between the two measurements on the same individual, thus turning the two measurements for each individual into one.</description>
    </item>
    
    <item>
      <title>Getting data from a frequency table, the tidyverse way</title>
      <link>/2018/06/01/getting-data-from-a-frequency-table-the-tidyverse-way/</link>
      <pubDate>Fri, 01 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/06/01/getting-data-from-a-frequency-table-the-tidyverse-way/</guid>
      <description>The usual package library(tidyverse) ## ── Attaching packages ────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 2.2.1.9000 ✔ purrr 0.2.4 ## ✔ tibble 1.4.2 ✔ dplyr 0.7.4 ## ✔ tidyr 0.8.0 ✔ stringr 1.3.0 ## ✔ readr 1.1.1 ✔ forcats 0.3.0 ## ── Conflicts ───────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag()  Introduction ⊕References at the end.
I was searching for some data for an assignment for my students, and I found an exercise in Watkins, Schaeffer and Cobb that seemed to fit my needs.</description>
    </item>
    
    <item>
      <title>Ken ventures into community ecology</title>
      <link>/2018/05/17/ken-ventures-into-community-ecology/</link>
      <pubDate>Thu, 17 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/05/17/ken-ventures-into-community-ecology/</guid>
      <description>Introduction Somebody mentioned ANOSIM to me, and I had this kind of vague recollection of it, meaning that I didn’t really understand anything of it at all. This prompted me to explore further, which got me into the vegan package. This contains a number of functions for handling ecological community data. One of these is anosim, or “analysis of similarity”, which is used for assessing the groupings of objects when we have only a dissimilarity matrix: are the objects within a group more similar than ones in different groups?</description>
    </item>
    
    <item>
      <title>Simulation, the tidy way</title>
      <link>/2018/05/14/simulation-the-tidy-way/</link>
      <pubDate>Mon, 14 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/05/14/simulation-the-tidy-way/</guid>
      <description>Packages I’m using this, and also doing some random number generation, which I’d like to be reproducible:
library(tidyverse) ## ── Attaching packages ────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 2.2.1.9000 ✔ purrr 0.2.4 ## ✔ tibble 1.4.2 ✔ dplyr 0.7.4 ## ✔ tidyr 0.8.0 ✔ stringr 1.3.0 ## ✔ readr 1.1.1 ✔ forcats 0.3.0 ## ── Conflicts ───────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() set.</description>
    </item>
    
    <item>
      <title>Tidy chi-squared testing</title>
      <link>/2018/04/12/tidy-chi-squared-testing/</link>
      <pubDate>Thu, 12 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/12/tidy-chi-squared-testing/</guid>
      <description>Introduction R has the creaky old functions table and chisq.test for counting up frequencies and doing chi-squared tests for association. They work, but there is nothing very tidyverse or elegant about them. Nonetheless, if we organize things right, we can use them in a tidy way, with everything working with data frames and pipelines.
 Packages I use broom later for tidy output:
library(tidyverse) ## ── Attaching packages ─────────────────────────────────────────────────────────────────────────── tidyverse 1.</description>
    </item>
    
    <item>
      <title>Simpson&#39;s paradox, log-linear modelling, and the tidyverse</title>
      <link>/2018/04/07/simpson-s-paradox-log-linear-modelling-and-the-tidyverse/</link>
      <pubDate>Sat, 07 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/07/simpson-s-paradox-log-linear-modelling-and-the-tidyverse/</guid>
      <description>Introduction I have some data on punctuality of arrivals at five different airports for two different airlines, thus:
 Alaska Airlines America West airport ontime delayed ontime delayed LosAngeles 497 62 694 117 Phoenix 221 12 4840 415 SanDiego 212 20 383 65 SanFrancisco 503 102 320 129 Seattle 1841 305 201 61 There are three variables: airport, airline and whatever the name is of the variable containing ontime and delayed (I’ll call it status).</description>
    </item>
    
    <item>
      <title>Today on Twitter I learned...</title>
      <link>/2018/03/25/today-on-twitter-i-learned/</link>
      <pubDate>Sun, 25 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/25/today-on-twitter-i-learned/</guid>
      <description>Introduction Today on Twitter I learned (or was reminded about) two #rstats things:
from @pkqstr about separate_rows from tidyr, that does something like separate followed by gather, but better. from @ma_salmon about haven for reading in data files from other software, and I thought about rio that does more or less the same thing, but more generally.  I didn’t come up with an answer to Maëlle’s question of why haven worked less well for me than rio a long time ago.</description>
    </item>
    
    <item>
      <title>Ward&#39;s method and dissimilarities</title>
      <link>/2018/03/22/ward-s-method-and-dissimilarities/</link>
      <pubDate>Thu, 22 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/22/ward-s-method-and-dissimilarities/</guid>
      <description>Introduction I don’t know yet where this post is going. Think of it, for now, as a ramble through cluster analysis. I may eventually figure out what to do with it, but I don’t want to delete what I have written just yet.
Hierarchical clustering is a way of forming groups or “clusters” of like individuals. The various forms of hierarchical clustering work from distances or dissimilarilities between individuals. The process is to start from each individual in a cluster by itself and then to join the closest pair of clusters one by one until all individuals are in a single cluster.</description>
    </item>
    
    <item>
      <title>Working my way back to you, a re-investigation of rstan</title>
      <link>/2018/02/28/working-my-way-back-to-you-a-re-investigation-of-rstan/</link>
      <pubDate>Wed, 28 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/02/28/working-my-way-back-to-you-a-re-investigation-of-rstan/</guid>
      <description>Introduction I learned Stan a while back, when I was fitting some Bayesian models. I wanted to fix up one of them, and I realized that I had forgotten most of what I knew about Stan, so I had to go back and learn it again.
A Bayesian model has two parts: a prior distribution, which summarizes your belief about the parameters you are trying to estimate before you look at any data, and a model that asserts the data-generating mechanism conditional on the parameter value(s).</description>
    </item>
    
    <item>
      <title>A brief foray into list-columns</title>
      <link>/2017/07/25/a-brief-foray-into-list-columns/</link>
      <pubDate>Tue, 25 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/07/25/a-brief-foray-into-list-columns/</guid>
      <description>Introduction Let’s suppose we are trying to find the median of a bunch of binomial distributions. ⊕This is a simplified version of an actual problem I had, but that one fails for some unconnected (and thus far unknown) reason, so I don’t want to show you that.
To be specific, let’s suppose we have these values of \(n\):
n=c(10,15,20) and these values of \(p\):
p=c(0.25,0.3,0.42) We’ll need the tidyverse, as usual:</description>
    </item>
    
    <item>
      <title>Summarizing several models using broom and purrr</title>
      <link>/2017/07/20/summarizing-several-models-using-broom-and-purrr/</link>
      <pubDate>Thu, 20 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/07/20/summarizing-several-models-using-broom-and-purrr/</guid>
      <description>Introduction broom is supposed to be a powerful way to summarize several models at once, and so it is. The trouble is, the examples show how to fit the same model to different subsets of a data set. I had something different in mind: I had one data set, and three different models on that same data. Could I do something similar there? It wasn’t clear to me how.
 Illustrative data The data here came from Albright’s book.</description>
    </item>
    
    <item>
      <title>Histograms and bins</title>
      <link>/2017/06/08/histograms-and-bins/</link>
      <pubDate>Thu, 08 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/06/08/histograms-and-bins/</guid>
      <description>Most software, when you ask it to draw you a histogram, will choose a number of intervals (“bins”) for you. Base R is one of those. To illustrate, let’s read in some data:
library(tidyverse) ## ── Attaching packages ────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 2.2.1.9000 ✔ purrr 0.2.4 ## ✔ tibble 1.4.2 ✔ dplyr 0.7.4 ## ✔ tidyr 0.8.0 ✔ stringr 1.3.0 ## ✔ readr 1.1.1 ✔ forcats 0.3.0 ## ── Conflicts ───────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() myurl=&amp;quot;http://www.</description>
    </item>
    
    <item>
      <title>Carter and Guthrie</title>
      <link>/2017/06/01/carter-and-guthrie/</link>
      <pubDate>Thu, 01 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/06/01/carter-and-guthrie/</guid>
      <description>Introduction Carter and Guthrie, in 2004, proposed a method of modelling cricket matches. Their aim was to provide an alternative method of deciding interrupted matches, in the manner of Duckworth and Lewis. What was interesting to me is that they estimate a probability of winning (which is then held fixed over interruptions), and it seemed to me that one could estimate and update the probability of winning as the game progresses, which would be a useful adjunct for spectators.</description>
    </item>
    
    <item>
      <title>Add-in</title>
      <link>/2017/05/22/add-in/</link>
      <pubDate>Mon, 22 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/05/22/add-in/</guid>
      <description>I just discovered a couple of things:
an R Studio add-in called CRANsearcher that, when you run it, prompts you for search terms and searches the whole of CRAN for anything that matches those search terms. (Thanks to @juliasilge on Twitter for this.) To install:  devtools::install_github(&amp;quot;RhoInc/CRANsearcher&amp;quot;) This inspired me to see what else was on my AddIns menu in R Studio. I also found options for creating a new blog post and “serving the site” so I can preview it.</description>
    </item>
    
    <item>
      <title>Welch analysis of variance</title>
      <link>/2017/05/19/welch-analysis-of-variance/</link>
      <pubDate>Fri, 19 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/05/19/welch-analysis-of-variance/</guid>
      <description>Introduction The standard analysis of variance based on the \(F\)-test has two major assumptions:
Normally distributed data Equal variance within each group.  The analysis can handle a certain amount of non-normality, but the equal-variance assumption is important because it is required for the idea of “an” error variance to make sense (that is what the error mean square is estimating).
Is it possible to make an ANOVA that can allow for the groups to have different variances?</description>
    </item>
    
  </channel>
</rss>