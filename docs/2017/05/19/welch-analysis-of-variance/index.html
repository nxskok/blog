<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

<head>
<title>Ken&#39;s Blog - Welch analysis of variance</title>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="">
<meta name="keywords" content="">
<meta name="author" content="Ken&#39;s Blog">
<meta name="generator" content="Hugo 0.20.6" />

  



<link rel="stylesheet" href="http://yui.yahooapis.com/pure/0.6.0/pure-min.css">


    <link rel="stylesheet" href="http://yui.yahooapis.com/pure/0.6.0/grids-responsive-min.css">








<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">


<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>


<link rel="stylesheet" href="../../../../css/tuftesque.css">

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-92165973-1', 'auto');
  ga('send', 'pageview');

</script>
</head>

<body>
<div id="layout" class="pure-g">
<article class="pure-u-1">
<header class="brand">
  <h1>
    <a href="../../../../">
      <span id = "blog_logo">
        
          <img src=/156-front.jpg alt="Blog Logo" style="height: 40px; width:40px">
        
      </span>
      
    </a>
  </h1>
</header>

<section>
  <h1 class="content-title">
  
  <a href="../../../../2017/05/19/welch-analysis-of-variance/">Welch analysis of variance</a>
  
  </h1>
  
  
  
  <span class="content-meta">
    
  
  
  
  
  
  
  <i class="fa fa-calendar"></i>
    &nbsp;May 19, 2017
  
  
  
  &nbsp;<i class="fa fa-clock-o"></i>
    &nbsp;9 min read
  
  
  
  <br>
    <i class="fa fa-tags"> </i>
    
    <a  href="../../../../categories/statistics">statistics</a>
    
    
    </span>
    
    
    </section>


<section><div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>The standard analysis of variance based on the <span class="math inline">\(F\)</span>-test has two major assumptions:</p>
<ol style="list-style-type: decimal">
<li>Normally distributed data</li>
<li>Equal variance within each group.</li>
</ol>
<p>The analysis can handle a certain amount of non-normality, but the equal-variance assumption is important because it is required for the idea of “an” error variance to make sense (that is what the error mean square is estimating).</p>
<p>Is it possible to make an ANOVA that can allow for the groups to have different variances? The answer is yes, and it’s the same mechanism as is behind the Welch-Satterthwaite <span class="math inline">\(t\)</span>-test, which we’ll review first.</p>
</div>
<div id="pooled-and-welch-satterthwaite-t-tests" class="section level2">
<h2>Pooled and Welch-Satterthwaite <span class="math inline">\(t\)</span>-tests</h2>
<p>If you have done statistical theory, you probably derived the pooled two-sample <span class="math inline">\(t\)</span>-test. This is for comparing the means of two populations based on samples from each. The assumptions are the same as for the ANOVA: normally-distributed data, with equal variances in the two groups. Since the two within-group variances are the same, there is only one “error variance” <span class="math inline">\(\sigma^2\)</span> to estimate, and this is estimated by <span class="math inline">\(s_p^2\)</span>, which is a weighted average of the sample variances from the two groups. The test statistic is then</p>
<p><span class="math display">\[ t =  { \bar{x}_1 - \bar{x}_2 \over
          s_p \sqrt{{1\over n_1}+ {1\over n_2}}} \]</span></p>
<p>and since there is <em>one</em> population variance <span class="math inline">\(\sigma^2\)</span> estimated by a sample variance <span class="math inline">\(s_p^2\)</span>, the test statistic <span class="math inline">\(t\)</span> does indeed have a exact <span class="math inline">\(t\)</span> distribution with as many degrees of freedom as <span class="math inline">\(s_p^2\)</span> does, namely <span class="math inline">\(n_1+n_2-2\)</span>.</p>
<p>What if the two groups have unequal variances? Welch and Satterthwaite (independently, as far as I know) had the idea of estimating the two separate <span class="math inline">\(\sigma^2\)</span>’s by the two sample variances and calculating this <span class="math inline">\(t\)</span>-statistic instead:</p>
<p><span class="math display">\[ t =  { \bar{x}_1 - \bar{x}_2 \over
          \sqrt{{s_1^2\over n_1}+ {s_2^2\over n_2}}} \]</span> which is the obvious thing. Unfortunately, however, this does <em>not</em> have a <span class="math inline">\(t\)</span> distribution, because <em>two</em> population variances have been estimated by sample variances.</p>
<p>Welch and Satterthwaite noticed that this <span class="math inline">\(t\)</span> does have a distribution that looks very like a <span class="math inline">\(t\)</span>, so they hit upon the idea of approximating it by a <span class="math inline">\(t\)</span>. They worked out the variance of this <span class="math inline">\(t\)</span> under the null hypothesis of equal means, and compared this to the variance of a <span class="math inline">\(t\)</span> distribution, which depends on its degrees of freedom. This allows a “method of moments” approximation of the degrees of freedom, which is the very complicated formula in a footnote in DeVeaux et al. The complication doesn’t matter in practice, though, since you let your software work out the (fractional) degrees of freedom and get a P-value. If you’re stuck doing this by hand, a “conservative” approximation to the df is the smaller sample size minus 1.</p>
<p>In practice, it is probably good to use the Welch-Satterthwaite <span class="math inline">\(t\)</span>-test as a default without thinking too hard about it, because the two group variances are not usually “approximately equal”, and it doesn’t make too much sense to act as if they are. That said, the Welch-Satterthwaite and pooled <span class="math inline">\(t\)</span>-tests often give similar results, as in the example below.</p>
<p>Some researchers are investigating a new method for teaching children to read. There are 44 children in their study; they randomly assign about half of the children to the new reading method (“treatment”) and about half to the standard reading method (“control”). The response variable was the score on a reading test, administered at the end of the study. The groups came out slightly unequal in size. Evidently, once a child has learned to read, they cannot learn to read again, so the design for this study had to be two independent samples rather than something like matched pairs.</p>
<p>Let’s load the Tidyverse:</p>
<pre class="r"><code>library(tidyverse)</code></pre>
<pre><code>## Loading tidyverse: ggplot2
## Loading tidyverse: tibble
## Loading tidyverse: tidyr
## Loading tidyverse: readr
## Loading tidyverse: purrr
## Loading tidyverse: dplyr</code></pre>
<pre><code>## Conflicts with tidy packages ----------------------------------------------</code></pre>
<pre><code>## filter(): dplyr, stats
## lag():    dplyr, stats</code></pre>
<p>and then read in the data, values separated by spaces:</p>
<pre class="r"><code>drp=read_delim(&quot;drp.txt&quot;,&quot; &quot;)</code></pre>
<pre><code>## Parsed with column specification:
## cols(
##   group = col_character(),
##   score = col_integer()
## )</code></pre>
<p>and summarize the values:</p>
<pre class="r"><code>drp %&gt;% group_by(group) %&gt;% 
  summarize(mean=mean(score),sd=sd(score))</code></pre>
<pre><code>## # A tibble: 2 x 3
##   group     mean       sd
##   &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;
## 1     c 41.52174 17.14873
## 2     t 51.47619 11.00736</code></pre>
<p>The means are 10 points different, and the immediate question is whether these are far enough apart to be significantly different. Note also, though, that the sample standard deviations are not that similar either. R’s <code>t.test</code> does the Welch-Satterthwaite test by default:</p>
<pre class="r"><code>t.test(score~group,data=drp,alternative=&quot;less&quot;)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  score by group
## t = -2.3109, df = 37.855, p-value = 0.01319
## alternative hypothesis: true difference in means is less than 0
## 95 percent confidence interval:
##       -Inf -2.691293
## sample estimates:
## mean in group c mean in group t 
##        41.52174        51.47619</code></pre>
<p>I did a one-sided test, since I wanted to see whether the new reading method was an <em>improvement</em>. At <span class="math inline">\(\alpha=0.05\)</span>, it is; the P-value is 0.0132.</p>
<p>What happens if we (evidently mistakenly) run the pooled <span class="math inline">\(t\)</span>-test here? That is done this way:</p>
<pre class="r"><code>t.test(score~group,data=drp,var.equal=T,alternative=&quot;less&quot;)</code></pre>
<pre><code>## 
##  Two Sample t-test
## 
## data:  score by group
## t = -2.2666, df = 42, p-value = 0.01431
## alternative hypothesis: true difference in means is less than 0
## 95 percent confidence interval:
##       -Inf -2.567497
## sample estimates:
## mean in group c mean in group t 
##        41.52174        51.47619</code></pre>
<p>The P-value, 0.0143, is very similar, and the conclusion at <span class="math inline">\(\alpha=0.05\)</span> is the same. Maybe the sample variances were “not too unequal”.</p>
</div>
<div id="the-welch-anova" class="section level2">
<h2>The Welch ANOVA</h2>
<p>Welch went on and applied his idea to the ANOVA <span class="math inline">\(F\)</span>-test. His idea was to leave the numerator df in the <span class="math inline">\(F\)</span> the same, but to tweak the denominator df to account for the groups having unequal variances.</p>
<p>Let’s illustrate using some data on jumping rats. The idea of the experiment was to see whether jumping (as a proxy for physical exercise) makes bones stronger. The rats were randomly divided into three groups: a control group, that did no extra jumping, and two treatment groups, one that jumped high (<code>highjump</code>) and one not so high (<code>lowjump</code>). Both treatment groups spent the same amount of time jumping. The idea with having two treatment groups was to see whether <em>any</em> exercise made a difference, or whether more vigorous exercise was what mattered. The response variable was bone density, a higher value meaning stronger bones.</p>
<pre class="r"><code>rats=read_delim(&quot;jumping.txt&quot;,&quot; &quot;)</code></pre>
<pre><code>## Parsed with column specification:
## cols(
##   group = col_character(),
##   density = col_integer()
## )</code></pre>
<p>Let’s look at boxplots by group:</p>
<pre class="r"><code>ggplot(rats,aes(x=group,y=density))+geom_boxplot()</code></pre>
<p><img src="../../../../post/welch_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>The control group has outliers, and the low-jumping group has larger spread than the high-jumping group (whose distribution looks skewed). Ignoring the apparent non-normality, what happens when we account for the differences in spread?</p>
<p>First, the regular ANOVA, which we are not at all sure we should trust:</p>
<pre class="r"><code>rats.1=aov(density~group,data=rats)
summary(rats.1)</code></pre>
<pre><code>##             Df Sum Sq Mean Sq F value Pr(&gt;F)   
## group        2   7434    3717   7.978 0.0019 **
## Residuals   27  12579     466                  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>and then the Welch ANOVA, which is done with <code>oneway.test</code>:</p>
<pre class="r"><code>rats.2=oneway.test(density~group,data=rats)
rats.2</code></pre>
<pre><code>## 
##  One-way analysis of means (not assuming equal variances)
## 
## data:  density and group
## F = 8.8164, num df = 2.000, denom df = 17.405, p-value = 0.002268</code></pre>
<p>The P-values are again not that different: 0.0019 vs. 0.0022. You see that the Welch ANOVA has a slightly different <span class="math inline">\(F\)</span> statistic (in the same way that the Welch-Satterthwaite <span class="math inline">\(t\)</span>-test has a slightly different <span class="math inline">\(t\)</span>-statistic), the numerator df is the same, but the denominator df is different, and fractional.</p>
<p>In any case, there are differences among the mean bone densities in the different groups.</p>
<p>The next question is to understand where the differences lie. With regular ANOVA, a standard method is Tukey’s:</p>
<pre class="r"><code>TukeyHSD(rats.1)</code></pre>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = density ~ group, data = rats)
## 
## $group
##                   diff       lwr       upr     p adj
## Highjump-Control  37.6  13.66604 61.533957 0.0016388
## Lowjump-Control   11.4 -12.53396 35.333957 0.4744032
## Lowjump-Highjump -26.2 -50.13396 -2.266043 0.0297843</code></pre>
<p>This says the that mean bone density for the high-jumping group is significantly higher than for the other two groups, which are not significantly different. This says, therefore, that it is the high jumping that makes a difference.</p>
<p>The standard follow-up for Welch’s ANOVA appears to be “Games-Howell”. This is part of the function <code>oneway</code> in the <code>userfriendlyscience</code> package:</p>
<pre class="r"><code>library(userfriendlyscience)
with(rats,oneway(x=group,y=density,posthoc=&quot;games-howell&quot;))</code></pre>
<pre><code>## Warning in oneway(x = group, y = density, posthoc = &quot;games-howell&quot;): ###
## Warning: the x variable (group) is not a factor! Converting it myself - but
## note that variables in R have data types, and it&#39;s advisable to set these
## adequately (use for example &#39;as.factor&#39;; see &#39;?as.factor&#39; for help)!</code></pre>
<pre><code>## ### Oneway Anova for y=density and x=group (groups: Control, Highjump, Lowjump)
## 
## Omega squared: 95% CI = [.07; .55], point estimate = .32
## Eta Squared: 95% CI = [.11; .52], point estimate = .37
## 
##                                      SS Df      MS    F    p
## Between groups (error + effect) 7433.87  2 3716.93 7.98 .002
## Within groups (error only)      12579.5 27  465.91          
## 
## 
## ### Post hoc test: games-howell
## 
##                   diff  ci.lo ci.hi    t    df    p p.adjusted
## Highjump-Control  37.6  11.28 63.92 3.72 14.83 0.01       .017
## Lowjump-Control   11.4 -15.90 38.70 1.08 16.19 0.54       .542
## Lowjump-Highjump -26.2 -46.80 -5.60 3.25 17.60 0.01       .024</code></pre>
<p>Note that the ANOVA at the top is the standard <span class="math inline">\(F\)</span>-test, not the Welch ANOVA, but the Games-Howell below is correct. The Games-Howell adjusted P-values differ slightly from Tukey, but tell exactly the same story: no difference between low jump and control, but high jump is better than both. We can therefore be more confident that the conclusions we drew before are not dependent on the unequal spreads.</p>
<p>The warning, by the way, is that the variable <code>group</code> is character rather than a factor (since <code>read_delim</code> does not turn strings into factors when reading from a file). Since the <code>group</code> column does successfully distinguish the groups, the warning can be ignored.</p>
</div>
<div id="conclusion" class="section level2">
<h2>Conclusion</h2>
<p>I would recommend doing the Welch ANOVA using <code>oneway.test</code> (worrying only about the approximate normality of the data, and not about equal variances), and follow up with Games-Howell (ignoring the first part of the <code>oneway</code> output). This would be consistent with routinely using the Welch-Satterthwaite <span class="math inline">\(t\)</span>-test over the pooled test, on the grounds that you never know whether the group variances are “sufficiently equal”. It is always possible to run the regular ANOVA and Tukey as well; if the results are similar, evidently the groups have similar variances and it doesn’t really matter what you do.</p>
<p>I think the Welch ANOVA deserves to be far better known.</p>
</div>
</section>
<section>
  


  <div id="disqus_thread"></div>
<script>
(function() {
var d = document, s = d.createElement('script');
s.src = 'https://kens-blog-2.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

  <footer class="page-footer">
		<hr>
		<ul class="page-footer-menu">
		
		</ul>

  

	<div class="copyright">
	<p>
    
      &copy; 2017
    .
    All rights reserved.
    
  </p>
</div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    });
    </script>
    <script type="text/javascript"
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
</footer>

</section>
</article>
</div>
</body>
</html>
