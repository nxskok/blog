---
title: Estimating sigma using quantiles
author: Ken
date: '2018-12-13'
slug: estimating-sigma-using-quantiles
categories:
  - R
  - statistics
tags:
  - '#rstats'
  - '#tidyverse'
---

## Packages

There will be some R later, with some random number generation. I set the random number seed for reproducibility:

```{r}
library(tidyverse)
set.seed(457299)
```


## Introduction

So, the other day, I was making normal quantile plots using SAS. As you do. I was using Simon Newcomb's famous data on the speed of light, and I used this code:

```
proc univariate noprint;
  qqplot Time / normal(mu=est sigma=est);
```

and got this output:

![](/qqplot1.png)

The idea of a normal quantile plot is that if your data really comes from a normal distribution, the points will follow the line (at least approximately), and the way in which they don't follow the line tells you how your data values are not normally distributed. I looked at this one and thought "well, these are not too bad, apart from that outlier at the bottom left", and the message seems to be that one of those values is much lower than the others. Thus, if you were using these data to estimate the true speed of light, it would be dangerous to use the sample mean, because it will be pulled downwards by that low value.

The way SAS adds a reference line to the normal quantile plot is to ask you to specify `mu` and `sigma` for the normal distribution. If you don't want to specify them, SAS is happy to estimate them, which it does the standard way using the sample mean and standard deviation. Or you can specify numeric values for them.

But, I thought, when you have outliers, or skewness, which you often will when you are using a normal quantile plot, the sample mean and standard deviation are the last things you should be using. But, SAS asks you to supply numbers for `mu` and `sigma`. What numbers are you going to use?

## Estimating `mu` and `sigma` using quantiles

A normal distribution is symmetric, so `mu` is equal to both its mean and its median. So, estimating `mu` is easy: if you are worried about outliers, use the sample median instead of the sample mean.

But how to estimate `sigma`? It is a measure of spread, so something to think about instead of the standard deviation would be a measure of spread like the interquartile range. This, like the median, won't be affected by outliers.

In a standard normal distribution, the quartiles are about $\pm 0.675$:

```{r}
q=c(0.25,0.75)
qnorm(q)
```

which means that the interquartile range is about $0.675-(-0.675)=1.35$. That is, the IQR is 1.35 times as big as the SD.  A normal distribution with SD $\sigma$ is a standard normal made wider by a factor $\sigma$ (and translated sideways by the mean), so the IQR of a general normal distribution is $1.35\sigma$. This means that we can estimate $\sigma$ by taking the sample interquartile range and dividing it by 1.35.

This may not be very efficient (in the sense that, if the data really are normal, you can estimate $\mu$ and $\sigma$ more accurately using the sample mean and SD), but our main aim here is to protect ourselves against trouble, and so this ought to be a reasonable idea. How does it play out here? Here is some of the Newcomb data:

```{r, echo=F}
"Newcomb" <-
structure(list(Time = c(2.4828e-05, 2.4826e-05, 2.4833e-05, 2.4824e-05, 
2.4834e-05, 2.4756e-05, 2.4827e-05, 2.4816e-05, 2.484e-05, 2.4798e-05, 
2.4829e-05, 2.4822e-05, 2.4824e-05, 2.4821e-05, 2.4825e-05, 2.483e-05, 
2.4823e-05, 2.4829e-05, 2.4831e-05, 2.4819e-05, 2.4824e-05, 2.482e-05, 
2.4836e-05, 2.4832e-05, 2.4836e-05, 2.4828e-05, 2.4825e-05, 2.4821e-05, 
2.4828e-05, 2.4829e-05, 2.4837e-05, 2.4825e-05, 2.4828e-05, 2.4826e-05, 
2.483e-05, 2.4832e-05, 2.4836e-05, 2.4826e-05, 2.483e-05, 2.4822e-05, 
2.4836e-05, 2.4823e-05, 2.4827e-05, 2.4827e-05, 2.4828e-05, 2.4827e-05, 
2.4831e-05, 2.4827e-05, 2.4826e-05, 2.4833e-05, 2.4826e-05, 2.4832e-05, 
2.4832e-05, 2.4824e-05, 2.4839e-05, 2.4828e-05, 2.4824e-05, 2.4825e-05, 
2.4832e-05, 2.4825e-05, 2.4829e-05, 2.4827e-05, 2.4828e-05, 2.4829e-05, 
2.4816e-05, 2.4823e-05), Series = as.integer(c(1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 
3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3))), .Names = c("Time", 
"Series"), class = "data.frame", row.names = c("1", "2", "3", 
"4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", 
"16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26", 
"27", "28", "29", "30", "31", "32", "33", "34", "35", "36", "37", 
"38", "39", "40", "41", "42", "43", "44", "45", "46", "47", "48", 
"49", "50", "51", "52", "53", "54", "55", "56", "57", "58", "59", 
"60", "61", "62", "63", "64", "65", "66"))
```

```{r}
Newcomb %>% slice(1:10)
```

The median and IQR are:

```{r}
(Newcomb %>% summarize(med=median(Time), iqr=IQR(Time)) -> d)
```

and thus our estimate of $\sigma$ is

```{r}
d$iqr/1.35
```

Putting those values in for `mu` and `sigma` gives this normal quantile plot:

![](/qqplot2.png)

The story is now quite different: there are actually *two* outliers at the bottom, and the rest of the observations are very close to what you'd expect in a normal distribution. This suggests that the bottom two observations are actually errors. Using the IQR to estimate `sigma` with seems to work very well for this purpose. This is the kind of thing R does with its normal quantile plot:

```{r}
ggplot(Newcomb, aes(sample=Time))+stat_qq()+stat_qq_line()
```

The help file says that the line goes through the observed and theoretical quartiles.

## Using other quantiles to estimate $\sigma$

But, I only used the quartiles because the IQR happened to come to mind as a measure of spread. The normal distribution is symmetric, so any pair of quantiles symmetrically placed about the mean (median) could be used, such as the 40th and 60th percentiles, or the 10th and 90th percentiles. If you choose percentiles further apart, you'll need to divide by something bigger to get a sensible estimate of $\sigma$. How big? Well,

```{r}
qnorm(0.90)-qnorm(0.10)
```

that big, if we use the 10th and 90th percentiles. `r tufte::margin_note("The discussion earlier also applies here: this is for a standard normal, but if the SD is not 1, the difference between 10th and 90th percentiles will still be 2.56  times whatever the SD is.")`

It seems like we should have a function that takes a quantile and returns that difference that we will need to divide by:

```{r}
divisor=function(p) {
  abs(qnorm(p)-qnorm(1-p))
}
```

and to test it on values where we know the answer already:

```{r}
divisor(c(0.10,0.25,0.75,0.90))
```

I used the `abs` in the function to allow for input of either the high end or the low end.

## Finding the best quantiles to estimate $\sigma$ with

I'm thinking that if you use a pair of quantiles too close to the centre of the distribution, you won't get too much sense of the spread, and if you use a pair of quantiles too far out in the tails, you'll get done in by the extremeness of the extreme values you happen to observe (which, in real data, might be outliers). So there ought to be a happy medium: a pair of quantiles not too far out that will estimate $\sigma$ more accurately than any other pair. 

We can do a simulation to find out whether this idea is right, and if it is, where the happy medium lies. The similarity in shape of the normal distribution for any value of $\sigma$ means that we can simulate from the standard normal and the results we get will apply for any $\sigma$.

Let's make a list of the quantiles we're going to use in the simulation (the low end):

```{r}
qq=c(0.01,0.025,0.05,0.075,0.1,0.15,0.20,0.25,0.4)
```

and generate some random normal data:

```{r}
(z=rnorm(50))
```

Let's make a table of divisors (that we calculate once and re-use):

```{r}
(tibble(lo=qq, hi=1-qq) %>% 
  mutate(div=divisor(lo)) -> divs)
```

and now we have to obtain all those quantiles for our random data, work out the differences, and divide by the right divisor:

```{r}
divs %>% mutate(z_lo=quantile(z,lo), z_hi=quantile(z,hi)) %>% 
  mutate(sigma_hat=(z_hi-z_lo)/div)
```

In this case, the estimate of $\sigma$ closest to the true value of 1 is 0.98, for the 10th and 90th percentiles.

We're going to do this lots of times in a moment, so let's make this into a function. It will have two inputs: the sample of random normals, and the table of quantiles and divisors. I'll return only the quantiles and estimates of sigma:

```{r}
estimates=function(z,divs) {
  divs %>% mutate(z_lo=quantile(z,lo), z_hi=quantile(z,hi)) %>% 
    mutate(sigma_hat=(z_hi-z_lo)/div) %>% 
    select(q=lo,sigma_hat)
}
```

To generate many random samples, I'll use `rerun`, which is the `tidyverse` version of the base R `replicate`. Let's start from small beginnings:

```{r}
rerun(5,rnorm(4))
```

This is 5 random samples of size 4, which come out in a list. I recently learned about `enframe`, which turns vectors and lists into two-column data frames:

```{r}
rerun(5,rnorm(4)) %>% 
  enframe()
```

The first column numbers the random samples, and the second contains the samples themselves, in a list-column. Now that we know how it works, let's generate bigger samples, and give the columns better names:

```{r}
rerun(5,rnorm(50)) %>% 
  enframe(name="sample_number", value="sample")
```

Next, for each of those samples, we want to generate the data frame of estimates of $\sigma$:

```{r}
rerun(5,rnorm(50)) %>% 
  enframe(name="sample_number", value="sample") %>% 
  mutate(ests=map(sample, ~estimates(.,divs)))
```

and then pull out the estimates so that we can summarize them:

```{r}
rerun(5,rnorm(50)) %>% 
  enframe(name="sample_number", value="sample") %>% 
  mutate(ests=map(sample, ~estimates(.,divs))) %>% 
  unnest(ests)
```

Compute the squared error of each estimate, and find the mean squared error for each quantile:

```{r}
rerun(5,rnorm(50)) %>% 
  enframe(name="sample_number", value="sample") %>% 
  mutate(ests=map(sample, ~estimates(.,divs))) %>% 
  unnest(ests) %>% 
  mutate(sq_error=(sigma_hat-1)^2) %>% 
  group_by(q) %>% 
  summarize(mse=mean(sq_error))
```

This was rather a small-scale simulation, but the best here is the 20th and 80th percentiles. Before we do a bigger simulation, let's put the above into a function with the sample size and number of simulations as inputs:

```{r}
simulate=function(n,n_sim) {
  rerun(n_sim,rnorm(n)) %>% 
    enframe(name="sample_number", value="sample") %>% 
    mutate(ests=map(sample, ~estimates(.,divs))) %>% 
    unnest(ests) %>% 
    mutate(sq_error=(sigma_hat-1)^2) %>% 
    group_by(q) %>% 
    summarize(mse=mean(sq_error))
}
```

and then do it for real:

```{r}
(d=simulate(50,10000))
```

This time the 7.5-92.5 percentile pair is best, and the 40-60 pair is clearly worst. Does that depend on sample size? Showing off a little:

```{r}
best_q=function(d) {
  d %>% arrange(mse) %>% pluck("q",1)
}
best_q(d)
tibble(n=c(10,20,50,100)) %>% 
  mutate(sims=map(n,~simulate(.,10000))) %>% 
  mutate(q=map_dbl(sims,~best_q(.)))
```


The 7.5-92.5 percentiles seem to be consistently the best.

## This has been done before

... and back in 1949, at that. Benson (1949) wrote about this, and noted (citing a 1920 paper of Karl Pearson) that the estimator of $\sigma$ with the smallest variance used the 7th and 93rd percentiles, for all sample sizes. My simulations are consistent with this.

Benson also estimated $\mu$ using the mean of a pair of quantiles, and said that the variance of the estimator was minimized when you use the mean of the 27th and 73rd percentiles. `r tufte::margin_note("This is almost the same thing as the midhinge, where hinge is Tukey's term for the quartile.")`

## An exam question

I had shown my students that you can estimate $\sigma$ by taking the IQR and dividing by 1.35, so on my final exam I played with that idea a bit more. I had them use the 68-95-99.7 rule (which they have seen before) to show that the 16th and 84th 
percentiles of a normal distribution are at $\mu \pm \sigma$, and thus that taking the difference between those two percentiles and dividing by 2 (since they are $2\sigma$ apart) is a sensible estimator of $\sigma$. (Had I included 0.16 as one of my quantiles above, `div` for it would have been 2.) I then gave them some data for which the 16th percentile was 26, the 84th percentile was 48, and the median was 36, and asked them to estimate $\mu$ and $\sigma$. I thought the "obvious" estimator of $\mu$ was the median, giving an estimate 36, but quite a lot of people noted that $\mu-\sigma=26$ and $\mu+\sigma=48$, and then solved the two equations for the two variables, getting estimates of *37* and 11. Full marks, of course. Little did they know, but on about the 70th anniversary of Benson's work, they were using his idea.

The idea for all of this came, in fact, from one of my students, who casually asked after class, "couldn't you use different percentiles to estimate $\sigma$ with?", and we talked about how you could, but you'd have to divide by something other than 1.35. 

## Future work

What would be relatively easy now (but this blog post is too long) is to compare the mean squared error of the best percentile-based estimator of $\sigma$ with that of the sample SD. If it turns out that the mean squared error of the percentile estimator is not too much bigger, then we could recommend using the percentile estimator because of the additional protection it gives when there are outliers. (This is the same idea as using the Welch-Satterthwaite $t$-test in favour of the pooled one; W-S is not the best test if the two groups have the same variance, but it is a *lot* better if the variances are actually different.)


## References

Reynold Jong (2018, personal communication, ie. a chat after class).

[Newcomb data](http://people.reed.edu/~jones/141/Newcomb.html)

Benson, F. (1949). A Note on the Estimation of Mean and Standard Deviation from Quantiles. Journal of the Royal Statistical Society. Series B (Methodological), 11(1), 91-100. Retrieved from [here](http://www.jstor.org.myaccess.library.utoronto.ca/stable/2983699)

[The midhinge](https://en.wikipedia.org/wiki/Midhinge)
